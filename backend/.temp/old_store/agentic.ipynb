{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0255b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pocketflow\n",
      "  Downloading pocketflow-0.0.2-py3-none-any.whl.metadata (329 bytes)\n",
      "Downloading pocketflow-0.0.2-py3-none-any.whl (3.3 kB)\n",
      "Installing collected packages: pocketflow\n",
      "Successfully installed pocketflow-0.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pocketflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd022c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pocketflow import Node, BatchNode, Flow\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ed0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "# Initialize Gemini client (ideally done once per app)\n",
    "client = genai.Client(api_key=\"AIzaSyDEaD5pWBhA3bzrKnYRV6vjwyw-7tUkCvs\")  # Replace with your actual API key\n",
    "\n",
    "def call_llm(prompt, model=\"gemini-2.0-flash\"):\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=model,\n",
    "            contents=prompt\n",
    "        )\n",
    "        return response.text  # The generated text response\n",
    "    except Exception as e:\n",
    "        print(\"LLM call failed:\", e)\n",
    "        return \"LLM call error\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e24ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 1: Generate Interview Questions\n",
    "class GenerateQuestions(Node):\n",
    "    def prep(self, shared):\n",
    "        return shared[\"resume\"], shared[\"interview_type\"] \n",
    "\n",
    "    def exec(self, inputs):\n",
    "        resume, interview_type = inputs\n",
    "        return f\"1. Tell me about your experience with Python.\\n2. How do you approach debugging?\\n3. Describe a challenging project.\\n4. What are your thoughts on clean code?\\n5. Explain a technical decision you made recently.\"\n",
    "\n",
    "    def post(self, shared, _, questions_text):\n",
    "        shared[\"questions\"] = questions_text.strip().split(\"\\n\")\n",
    "        return \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905255fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 2: Evaluate Candidate Answers\n",
    "class EvaluateAnswers(BatchNode):\n",
    "    def prep(self, shared):\n",
    "        return list(zip(shared[\"questions\"], shared[\"answers\"]))\n",
    "\n",
    "    def exec(self, qa_pair):\n",
    "        question, answer = qa_pair\n",
    "        prompt = f\"\"\"\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "\n",
    "Evaluate and return a score (1-10) and feedback:\n",
    "```yaml\n",
    "score: <score>\n",
    "feedback: <feedback>\n",
    "```\"\"\"\n",
    "        response = call_llm(prompt)\n",
    "        yaml_part = response.split(\"```yaml\")[1].split(\"```\")[0].strip()\n",
    "        return yaml.safe_load(yaml_part)\n",
    "\n",
    "    def post(self, shared, _, results):\n",
    "        shared[\"evaluations\"] = results\n",
    "        return \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 3: Summarize the Interview\n",
    "class SummarizeInterview(Node):\n",
    "    def prep(self, shared):\n",
    "        return shared[\"evaluations\"]\n",
    "\n",
    "    def exec(self, evaluations):\n",
    "        total = sum(e[\"score\"] for e in evaluations)\n",
    "        avg = total / len(evaluations)\n",
    "        feedback = \"\\n\".join([f\"Q{i+1}: {e['feedback']}\" for i, e in enumerate(evaluations)])\n",
    "        return f\"\"\"Overall Score: {avg:.1f}/10\\n\\nDetailed Feedback:\\n{feedback}\"\"\"\n",
    "\n",
    "    def post(self, shared, _, result):\n",
    "        shared[\"summary\"] = result\n",
    "        return \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595ebb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the flow\n",
    "qgen = GenerateQuestions()\n",
    "eval = EvaluateAnswers()\n",
    "summ = SummarizeInterview()\n",
    "\n",
    "qgen >> eval >> summ\n",
    "flow = Flow(start=qgen)\n",
    "\n",
    "# Example execution\n",
    "if __name__ == \"__main__\":\n",
    "    shared = {\n",
    "        \"resume\": \"John Doe: Python dev, 5 years experience in web backend, SQL, Flask.\",\n",
    "        \"interview_type\": \"technical\",\n",
    "        \"answers\": [\n",
    "            \"I have worked with Python for over 5 years...\",\n",
    "            \"My debugging process starts with...\",\n",
    "            \"A project I found challenging was...\",\n",
    "            \"I follow clean code principles like...\",\n",
    "            \"Recently, I chose PostgreSQL over MongoDB because...\"\n",
    "        ]\n",
    "    }\n",
    "    flow.run(shared)\n",
    "    print(\"\\n=== INTERVIEW SUMMARY ===\\n\")\n",
    "    print(shared[\"summary\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
